#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•è„šæœ¬ï¼šæµ‹è¯• Token æ¶ˆè€— / ç”Ÿæˆç¨³å®šæ€§ / è¯é¢˜è¦†ç›–èƒ½åŠ›
"""

import asyncio
import json
import os
import re
import time
from datetime import datetime
from typing import Dict, List, Any
from dotenv import load_dotenv

load_dotenv()

from workflow.backend.graph import Graph

# 15ä¸ªå¤šæ ·åŒ–è¯é¢˜ï¼Œè¦†ç›–ä¸åŒç±»åˆ«
TEST_TOPICS = [
    # ç»æµ/é‡‘èç±»
    {'topic': '2025å¹´ç¾è”å‚¨é™æ¯è‡³å°‘3æ¬¡', 'category': 'ç»æµ/è´§å¸æ”¿ç­–', 'date': '2025-12-31'},
    {'topic': 'æ¯”ç‰¹å¸2025å¹´çªç ´15ä¸‡ç¾å…ƒ', 'category': 'åŠ å¯†è´§å¸', 'date': '2025-12-31'},
    {'topic': 'ç‰¹æ–¯æ‹‰è‚¡ä»·2025å¹´ç¿»å€', 'category': 'è‚¡ç¥¨', 'date': '2025-12-31'},
    
    # æ”¿æ²»/åœ°ç¼˜ç±»
    {'topic': '2025å¹´ä¿„ä¹Œæˆ˜äº‰åœç«åè®®ç­¾ç½²', 'category': 'åœ°ç¼˜æ”¿æ²»', 'date': '2025-12-31'},
    {'topic': '2025å¹´ä¸­ç¾å…³ç¨å…¨é¢å–æ¶ˆ', 'category': 'å›½é™…è´¸æ˜“', 'date': '2025-12-31'},
    
    # ç§‘æŠ€ç±»
    {'topic': 'OpenAIå‘å¸ƒGPT-5', 'category': 'äººå·¥æ™ºèƒ½', 'date': '2025-12-31'},
    {'topic': 'è‹¹æœ2025å¹´å‘å¸ƒARçœ¼é•œ', 'category': 'æ¶ˆè´¹ç”µå­', 'date': '2025-12-31'},
    {'topic': 'SpaceXæ˜Ÿèˆ°æˆåŠŸè¿›å…¥ç«æ˜Ÿè½¨é“', 'category': 'èˆªå¤©', 'date': '2026-12-31'},
    
    # ä½“è‚²ç±»
    {'topic': '2026å¹´ä¸–ç•Œæ¯é˜¿æ ¹å»·å«å†•æˆåŠŸ', 'category': 'ä½“è‚²/è¶³çƒ', 'date': '2026-07-19'},
    {'topic': '2028æ´›æ‰çŸ¶å¥¥è¿ä¼šä¸­å›½é‡‘ç‰Œç¬¬ä¸€', 'category': 'ä½“è‚²/å¥¥è¿', 'date': '2028-08-11'},
    
    # æ°”å€™/ç¯å¢ƒç±»
    {'topic': '2025å¹´å…¨çƒå¹³å‡æ°”æ¸©åˆ›å†å²æ–°é«˜', 'category': 'æ°”å€™', 'date': '2025-12-31'},
    
    # å…¬å…±å«ç”Ÿç±»
    {'topic': 'WHOå®£å¸ƒæ–°å† å¤§æµè¡Œæ­£å¼ç»“æŸ', 'category': 'å…¬å…±å«ç”Ÿ', 'date': '2025-12-31'},
    
    # å•†ä¸š/ä¼ä¸šç±»
    {'topic': 'è‹±ä¼Ÿè¾¾å¸‚å€¼2025å¹´è¶…è¿‡è‹¹æœ', 'category': 'ç§‘æŠ€è‚¡', 'date': '2025-12-31'},
    
    # è‡ªç„¶ç¾å®³ç±»ï¼ˆé«˜ä¸ç¡®å®šæ€§ï¼‰
    {'topic': '2025å¹´æ—¥æœ¬å‘ç”Ÿ8çº§ä»¥ä¸Šåœ°éœ‡', 'category': 'è‡ªç„¶ç¾å®³', 'date': '2025-12-31'},
    
    # å¨±ä¹ç±»
    {'topic': '2025å¹´å¥¥æ–¯å¡æœ€ä½³å½±ç‰‡ç”±AIç”Ÿæˆç”µå½±è·å¾—', 'category': 'å¨±ä¹', 'date': '2025-03-02'},
]


def estimate_tokens(text: str) -> int:
    """ç²—ç•¥ä¼°ç®— token æ•°é‡ï¼ˆä¸­æ–‡çº¦ 1.5 å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦/tokenï¼‰"""
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    other_chars = len(text) - chinese_chars
    return int(chinese_chars / 1.5 + other_chars / 4)


def extract_scores(report: str) -> Dict[str, Any]:
    """ä»æŠ¥å‘Šä¸­æå–è¯„åˆ†"""
    scores = {
        'quantifiability': None,
        'oracle': None,
        'market_demand': None,
        'compliance_risk': None,
        'overall': None,
        'recommendation': None
    }
    
    # åŒ¹é…è¯„åˆ†æ¨¡å¼
    patterns = {
        'quantifiability': r'å¯é‡åŒ–æ€§[^0-9]*?(\d+)/10|ç»´åº¦è¯„åˆ†[ï¼š:]\s*(\d+)/10.*?å¯é‡åŒ–',
        'oracle': r'é¢„è¨€æœº[^0-9]*?(\d+)/10|ç»“ç®—æœºåˆ¶è¯„åˆ†[ï¼š:]\s*(\d+)/10',
        'market_demand': r'å¸‚åœºéœ€æ±‚[^0-9]*?(\d+)/10|éœ€æ±‚è¯„åˆ†[ï¼š:]\s*(\d+)/10',
        'compliance_risk': r'åˆè§„[^0-9]*?(\d+)/10|é£é™©è¯„åˆ†[ï¼š:]\s*(\d+)/10',
        'overall': r'æ€»è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)/10|ç»¼åˆ[å¾—è¯„]åˆ†[ï¼š:]\s*(\d+\.?\d*)/10'
    }
    
    for key, pattern in patterns.items():
        match = re.search(pattern, report, re.IGNORECASE)
        if match:
            for g in match.groups():
                if g:
                    scores[key] = float(g)
                    break
    
    # æå–æ¨èå†³ç­–
    if 'æ¨èä¸Šçº¿' in report:
        scores['recommendation'] = 'æ¨èä¸Šçº¿'
    elif 'è°¨æ…ä¸Šçº¿' in report:
        scores['recommendation'] = 'è°¨æ…ä¸Šçº¿'
    elif 'ä¸æ¨è' in report or 'æš‚ä¸æ¨è' in report:
        scores['recommendation'] = 'ä¸æ¨èä¸Šçº¿'
    
    return scores


def check_report_structure(report: str) -> Dict[str, bool]:
    """æ£€æŸ¥æŠ¥å‘Šç»“æ„å®Œæ•´æ€§"""
    required_sections = {
        'äº‹ä»¶æ¦‚è¿°': bool(re.search(r'##.*äº‹ä»¶æ¦‚è¿°|## äº‹ä»¶æ¦‚è¿°', report)),
        'å¯é‡åŒ–æ€§è¯„ä¼°': bool(re.search(r'##.*å¯é‡åŒ–æ€§|## å¯é‡åŒ–æ€§è¯„ä¼°', report)),
        'é¢„è¨€æœºä¸ç»“ç®—': bool(re.search(r'##.*é¢„è¨€æœº|## é¢„è¨€æœº', report)),
        'å¸‚åœºéœ€æ±‚åˆ†æ': bool(re.search(r'##.*å¸‚åœºéœ€æ±‚|## å¸‚åœºéœ€æ±‚', report)),
        'åˆè§„ä¸é£é™©': bool(re.search(r'##.*åˆè§„|## åˆè§„', report)),
        'ç»¼åˆç»“è®º': bool(re.search(r'##.*ç»¼åˆç»“è®º|## ç»¼åˆç»“è®º|##.*ç»“è®º', report)),
    }
    return required_sections


async def run_single_test(topic_info: Dict, index: int) -> Dict[str, Any]:
    """è¿è¡Œå•ä¸ªè¯é¢˜æµ‹è¯•"""
    result = {
        'index': index + 1,
        'topic': topic_info['topic'],
        'category': topic_info['category'],
        'status': 'pending',
        'time_seconds': 0,
        'report_length': 0,
        'estimated_tokens': 0,
        'scores': {},
        'structure': {},
        'structure_complete': False,
        'error': None
    }
    
    start_time = time.time()
    
    try:
        print(f"\n[{index+1}/{len(TEST_TOPICS)}] ğŸ”„ æµ‹è¯•ä¸­: {topic_info['topic']}")
        
        g = Graph(
            topic=topic_info['topic'],
            event_category=topic_info['category'],
            target_date=topic_info['date'],
            job_id=f'comprehensive-test-{index+1}'
        )
        
        thread = {'configurable': {'thread_id': f'test-thread-{index+1}'}}
        final_report = None
        
        async for state in g.run(thread):
            if 'editor' in state and state['editor'].get('report'):
                final_report = state['editor']['report']
        
        elapsed = time.time() - start_time
        result['time_seconds'] = round(elapsed, 1)
        
        if final_report:
            result['status'] = 'success'
            result['report_length'] = len(final_report)
            result['estimated_tokens'] = estimate_tokens(final_report)
            result['scores'] = extract_scores(final_report)
            result['structure'] = check_report_structure(final_report)
            result['structure_complete'] = all(result['structure'].values())
            
            # ä¿å­˜æŠ¥å‘Š
            safe_name = topic_info['topic'].replace('/', '_').replace(' ', '_')[:30]
            filename = f'reports/comprehensive_{index+1:02d}_{safe_name}.md'
            os.makedirs('reports', exist_ok=True)
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(final_report)
            
            print(f"    âœ… æˆåŠŸ | {elapsed:.1f}s | {result['report_length']}å­— | ~{result['estimated_tokens']}tokens")
            print(f"       è¯„åˆ†: é‡åŒ–{result['scores'].get('quantifiability', '?')}/é¢„è¨€æœº{result['scores'].get('oracle', '?')}/éœ€æ±‚{result['scores'].get('market_demand', '?')}/åˆè§„{result['scores'].get('compliance_risk', '?')}")
        else:
            result['status'] = 'failed'
            result['error'] = 'No report generated'
            print(f"    âŒ å¤±è´¥: æ— æŠ¥å‘Šç”Ÿæˆ")
            
    except Exception as e:
        elapsed = time.time() - start_time
        result['status'] = 'error'
        result['time_seconds'] = round(elapsed, 1)
        result['error'] = str(e)[:200]
        print(f"    âŒ é”™è¯¯: {str(e)[:100]}")
    
    return result


async def main():
    print("=" * 70)
    print("ğŸ§ª äº‹ä»¶æœŸè´§å¯è¡Œæ€§æŠ¥å‘Š - ç»¼åˆæµ‹è¯•")
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“Š æµ‹è¯•è¯é¢˜æ•°: {len(TEST_TOPICS)}")
    print("=" * 70)
    
    all_results = []
    total_start = time.time()
    
    # é¡ºåºæ‰§è¡Œæµ‹è¯•
    for i, topic in enumerate(TEST_TOPICS):
        result = await run_single_test(topic, i)
        all_results.append(result)
    
    total_time = time.time() - total_start
    
    # æ±‡æ€»ç»Ÿè®¡
    print("\n" + "=" * 70)
    print("ğŸ“ˆ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    success_results = [r for r in all_results if r['status'] == 'success']
    failed_results = [r for r in all_results if r['status'] != 'success']
    
    # 1. åŸºç¡€ç»Ÿè®¡
    print(f"\n### 1. åŸºç¡€ç»Ÿè®¡")
    print(f"   æˆåŠŸç‡: {len(success_results)}/{len(all_results)} ({100*len(success_results)/len(all_results):.1f}%)")
    print(f"   æ€»è€—æ—¶: {total_time:.1f}ç§’")
    print(f"   å¹³å‡è€—æ—¶: {total_time/len(all_results):.1f}ç§’/è¯é¢˜")
    
    if success_results:
        avg_length = sum(r['report_length'] for r in success_results) / len(success_results)
        avg_tokens = sum(r['estimated_tokens'] for r in success_results) / len(success_results)
        print(f"   å¹³å‡æŠ¥å‘Šé•¿åº¦: {avg_length:.0f}å­—ç¬¦")
        print(f"   å¹³å‡Tokenæ¶ˆè€—: ~{avg_tokens:.0f} tokens/æŠ¥å‘Š")
    
    # 2. Tokenæ¶ˆè€—åˆ†æ
    print(f"\n### 2. Tokenæ¶ˆè€—åˆ†æ")
    if success_results:
        tokens = [r['estimated_tokens'] for r in success_results]
        print(f"   æœ€å°: ~{min(tokens)} tokens")
        print(f"   æœ€å¤§: ~{max(tokens)} tokens")
        print(f"   å¹³å‡: ~{sum(tokens)/len(tokens):.0f} tokens")
        print(f"   æ€»è®¡: ~{sum(tokens)} tokens (ä»…è¾“å‡º)")
        # ä¼°ç®—è¾“å…¥tokenï¼ˆå‡è®¾è¾“å…¥æ˜¯è¾“å‡ºçš„2å€ï¼‰
        estimated_input = sum(tokens) * 2
        print(f"   ä¼°ç®—è¾“å…¥: ~{estimated_input} tokens")
        print(f"   ä¼°ç®—æ€»æ¶ˆè€—: ~{sum(tokens) + estimated_input} tokens")
    
    # 3. ç”Ÿæˆç¨³å®šæ€§åˆ†æ
    print(f"\n### 3. ç”Ÿæˆç¨³å®šæ€§åˆ†æ")
    structure_complete_count = sum(1 for r in success_results if r.get('structure_complete', False))
    print(f"   ç»“æ„å®Œæ•´ç‡: {structure_complete_count}/{len(success_results)} ({100*structure_complete_count/max(1,len(success_results)):.1f}%)")
    
    # æ£€æŸ¥å„éƒ¨åˆ†å®Œæˆæƒ…å†µ
    section_stats = {}
    for r in success_results:
        for section, present in r.get('structure', {}).items():
            if section not in section_stats:
                section_stats[section] = {'present': 0, 'missing': 0}
            if present:
                section_stats[section]['present'] += 1
            else:
                section_stats[section]['missing'] += 1
    
    print("   å„éƒ¨åˆ†ç”Ÿæˆç‡:")
    for section, stats in section_stats.items():
        rate = 100 * stats['present'] / (stats['present'] + stats['missing'])
        status = "âœ…" if rate == 100 else "âš ï¸" if rate >= 80 else "âŒ"
        print(f"     {status} {section}: {rate:.0f}%")
    
    # 4. è¯„åˆ†åˆ†å¸ƒ
    print(f"\n### 4. è¯„åˆ†åˆ†å¸ƒ")
    score_fields = ['quantifiability', 'oracle', 'market_demand', 'compliance_risk', 'overall']
    for field in score_fields:
        scores = [r['scores'].get(field) for r in success_results if r['scores'].get(field) is not None]
        if scores:
            avg = sum(scores) / len(scores)
            field_cn = {'quantifiability': 'å¯é‡åŒ–æ€§', 'oracle': 'é¢„è¨€æœº', 'market_demand': 'å¸‚åœºéœ€æ±‚', 
                       'compliance_risk': 'åˆè§„é£é™©', 'overall': 'ç»¼åˆè¯„åˆ†'}
            print(f"   {field_cn.get(field, field)}: å¹³å‡{avg:.1f}/10 (èŒƒå›´{min(scores)}-{max(scores)}, n={len(scores)})")
    
    # 5. æ¨èåˆ†å¸ƒ
    print(f"\n### 5. æ¨èå†³ç­–åˆ†å¸ƒ")
    recommendations = [r['scores'].get('recommendation') for r in success_results]
    rec_counts = {}
    for rec in recommendations:
        if rec:
            rec_counts[rec] = rec_counts.get(rec, 0) + 1
    for rec, count in sorted(rec_counts.items(), key=lambda x: -x[1]):
        print(f"   {rec}: {count}ä¸ª ({100*count/len(success_results):.1f}%)")
    
    # 6. è¯é¢˜è¦†ç›–èƒ½åŠ›
    print(f"\n### 6. è¯é¢˜è¦†ç›–èƒ½åŠ›")
    category_results = {}
    for r in all_results:
        cat = r['category']
        if cat not in category_results:
            category_results[cat] = {'success': 0, 'total': 0, 'topics': []}
        category_results[cat]['total'] += 1
        category_results[cat]['topics'].append(r['topic'][:20])
        if r['status'] == 'success':
            category_results[cat]['success'] += 1
    
    print("   æŒ‰ç±»åˆ«æˆåŠŸç‡:")
    for cat, stats in sorted(category_results.items()):
        rate = 100 * stats['success'] / stats['total']
        status = "âœ…" if rate == 100 else "âŒ"
        print(f"     {status} {cat}: {stats['success']}/{stats['total']}")
    
    # 7. å¤±è´¥æ¡ˆä¾‹
    if failed_results:
        print(f"\n### 7. å¤±è´¥æ¡ˆä¾‹")
        for r in failed_results:
            print(f"   âŒ {r['topic']}: {r.get('error', 'Unknown error')[:80]}")
    
    # 8. è¯¦ç»†ç»“æœè¡¨
    print(f"\n### 8. è¯¦ç»†ç»“æœ")
    print(f"{'#':<3} {'è¯é¢˜':<25} {'ç±»åˆ«':<12} {'çŠ¶æ€':<6} {'è€—æ—¶':<8} {'å­—æ•°':<8} {'Tokens':<8} {'ç»¼åˆåˆ†':<6}")
    print("-" * 90)
    for r in all_results:
        status = "âœ…" if r['status'] == 'success' else "âŒ"
        overall = r['scores'].get('overall', '-') if r['status'] == 'success' else '-'
        print(f"{r['index']:<3} {r['topic'][:24]:<25} {r['category'][:11]:<12} {status:<6} {r['time_seconds']:<8} {r['report_length']:<8} {r['estimated_tokens']:<8} {overall}")
    
    # ä¿å­˜JSONç»“æœ
    with open('reports/comprehensive_test_results.json', 'w', encoding='utf-8') as f:
        json.dump({
            'test_time': datetime.now().isoformat(),
            'total_topics': len(TEST_TOPICS),
            'success_count': len(success_results),
            'total_time_seconds': round(total_time, 1),
            'avg_time_per_topic': round(total_time / len(all_results), 1),
            'avg_tokens': round(sum(r['estimated_tokens'] for r in success_results) / max(1, len(success_results))),
            'results': all_results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° reports/comprehensive_test_results.json")
    print("=" * 70)


if __name__ == '__main__':
    asyncio.run(main())
