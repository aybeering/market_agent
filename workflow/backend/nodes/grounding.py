import logging
import os

from langchain_core.messages import AIMessage
from tavily import AsyncTavilyClient

from ..classes import InputState, ResearchState
from ..classes.state import job_status

logger = logging.getLogger(__name__)

class GroundingNode:
    """è§£æžäº‹ä»¶è¯é¢˜ï¼Œæ”¶é›†äº‹ä»¶èƒŒæ™¯ä¿¡æ¯ã€‚"""
    
    def __init__(self) -> None:
        self.tavily_client = AsyncTavilyClient(api_key=os.getenv("TAVILY_API_KEY"))

    async def initial_search(self, state: InputState):
        """åˆå§‹æœç´¢äº‹ä»¶èƒŒæ™¯ä¿¡æ¯å¹¶ç”Ÿæˆäº‹ä»¶"""
        topic = state.get('topic', 'Unknown Topic')
        job_id = state.get('job_id')
        msg = f"ðŸŽ¯ å¼€å§‹åˆ†æžäº‹ä»¶: {topic}...\n"
        
        # Emit initialization event
        event = {
            "type": "research_init",
            "topic": topic,
            "message": f"å¼€å§‹åˆ†æžäº‹ä»¶: {topic}",
            "step": "åˆå§‹åŒ–"
        }
        
        if job_id:
            try:
                if job_id in job_status:
                    job_status[job_id]["events"].append(event)
            except Exception as e:
                logger.error(f"Error appending research_init event: {e}")
        
        yield event

        event_background = {}

        # æœç´¢äº‹ä»¶èƒŒæ™¯ä¿¡æ¯
        msg += f"\nðŸ” æœç´¢äº‹ä»¶èƒŒæ™¯: {topic}"
        logger.info(f"Starting event background search for {topic}")
        
        # Emit search start event
        event = {
            "type": "background_search_start",
            "topic": topic,
            "message": f"æœç´¢äº‹ä»¶èƒŒæ™¯ä¿¡æ¯: {topic}",
            "step": "äº‹ä»¶èƒŒæ™¯æœç´¢"
        }
        
        if job_id:
            try:
                if job_id in job_status:
                    job_status[job_id]["events"].append(event)
            except Exception as e:
                logger.error(f"Error appending background_search_start event: {e}")
        
        yield event

        try:
            logger.info("Initiating Tavily search for event background")
            
            # æœç´¢äº‹ä»¶åŸºæœ¬ä¿¡æ¯
            search_result = await self.tavily_client.search(
                query=f"{topic} äº‹ä»¶è¯¦æƒ… èƒŒæ™¯",
                search_depth="basic",  # Changed from advanced for speed
                max_results=5  # Reduced from 10 for speed
            )
            
            for item in search_result.get("results", []):
                if item.get("content"):
                    url = item.get("url", "")
                    event_background[url] = {
                        'title': item.get('title', ''),
                        'content': item.get('content', ''),
                        'url': url,
                        'source': 'background_search',
                        'score': item.get('score', 0.0)
                    }
            
            if event_background:
                logger.info(f"Successfully found {len(event_background)} background documents")
                msg += f"\nâœ… æ‰¾åˆ° {len(event_background)} ä»½èƒŒæ™¯æ–‡æ¡£"
                yield {
                    "type": "background_search_success",
                    "docs_found": len(event_background),
                    "message": f"æ‰¾åˆ° {len(event_background)} ä»½èƒŒæ™¯æ–‡æ¡£",
                    "step": "äº‹ä»¶èƒŒæ™¯æœç´¢"
                }
            else:
                logger.warning("No background content found")
                msg += "\nâš ï¸ æœªæ‰¾åˆ°èƒŒæ™¯ä¿¡æ¯"
                yield {
                    "type": "background_search_warning",
                    "message": "âš ï¸ æœªæ‰¾åˆ°äº‹ä»¶èƒŒæ™¯ä¿¡æ¯",
                    "step": "äº‹ä»¶èƒŒæ™¯æœç´¢"
                }
        except Exception as e:
            error_str = str(e)
            logger.error(f"Background search error: {error_str}", exc_info=True)
            error_msg = f"âš ï¸ æœç´¢äº‹ä»¶èƒŒæ™¯æ—¶å‡ºé”™: {error_str}"
            msg += f"\n{error_msg}"
            yield {
                "type": "background_search_error",
                "error": error_str,
                "message": error_msg,
                "step": "äº‹ä»¶èƒŒæ™¯æœç´¢",
                "continue_research": True
            }

        # Add context about what information we have
        context_data = {}
        if event_category := state.get('event_category'):
            msg += f"\nðŸ“‚ äº‹ä»¶ç±»åˆ«: {event_category}"
            context_data["event_category"] = event_category
        if target_date := state.get('target_date'):
            msg += f"\nðŸ“… é¢„æœŸç»“ç®—æ—¥æœŸ: {target_date}"
            context_data["target_date"] = target_date
        if event_description := state.get('event_description'):
            msg += f"\nðŸ“ äº‹ä»¶æè¿°: {event_description[:100]}..."
            context_data["event_description"] = event_description
        
        # Initialize ResearchState with input information
        research_state = {
            # Copy input fields
            "topic": state.get('topic'),
            "event_description": state.get('event_description'),
            "event_category": state.get('event_category'),
            "target_date": state.get('target_date'),
            "job_id": state.get('job_id'),
            # Initialize research fields
            "messages": [AIMessage(content=msg)],
            "event_background": event_background
        }

        yield {"type": "grounding_complete", "background_docs": len(event_background)}
        yield research_state

    async def run(self, state: InputState) -> ResearchState:
        """Run grounding - note: for now returns directly, events can be captured if needed"""
        result = None
        async for event in self.initial_search(state):
            if isinstance(event, dict) and "type" not in event:
                result = event
        return result if result else {}
